{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top Wikipedia pages, [according to Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Popular_pages#Top-100_list).\n",
    "\n",
    "Rank | Page | Views in millions\n",
    "-----|------|------------------\n",
    "1 | United States | 237\n",
    "2 | Donald Trump | 233\n",
    "3 | Barack Obama | 155\n",
    "3 | Elizabeth II | 155\n",
    "5 | India | 151\n",
    "6 | World War II | 136\n",
    "7 | Michael Jackson | 133\n",
    "7 | United Kingdom | 133\n",
    "9 | Cristiano Ronaldo | 131\n",
    "10 | Lady Gaga | 124\n",
    "11 | Sex | 123\n",
    "12 | Adolf Hitler | 121\n",
    "13 | Eminem | 120\n",
    "14 | Game of Thrones | 116\n",
    "15 | World War I | 113\n",
    "16 | The Beatles | 112\n",
    "17 | Justin Bieber | 109\n",
    "18 | Elon Musk | 108\n",
    "19 | Canada | 106\n",
    "19 | Freddie Mercury | 106\n",
    "21 | Lionel Messi | 105\n",
    "22 | Kim Kardashian | 104\n",
    "23 | Steve Jobs | 103\n",
    "24 | Michael Jordan | 100\n",
    "24 | Dwayne Johnson | 100\n",
    "24 | The Big Bang Theory | 100\n",
    "24 | List of Presidents of the United States | 100\n",
    "24 | Australia | 100\n",
    "29 | Stephen Hawking | 97\n",
    "30 | Taylor Swift | 94\n",
    "31 | List of highest-grossing films | 93\n",
    "31 | China | 93\n",
    "33 | Darth Vader | 91\n",
    "34 | Star Wars | 90\n",
    "34 | Miley Cyrus | 90\n",
    "34 | Abraham Lincoln | 90\n",
    "37 | September 11 attacks | 89\n",
    "38 | Lil Wayne | 88\n",
    "38 | Academy Awards | 88\n",
    "38 | Japan | 88\n",
    "38 | Johnny Depp | 88\n",
    "38 | Germany | 88\n",
    "38 | LeBron James | 88\n",
    "38 | New York City | 88\n",
    "45 | Harry Potter | 86\n",
    "45 | Kobe Bryant | 86\n",
    "45 | Selena Gomez | 86\n",
    "45 | Leonardo DiCaprio | 86\n",
    "45 | Rihanna | 86\n",
    "45 | Albert Einstein | 86\n",
    "45 | Russia | 86\n",
    "52 | The Walking Dead (TV series) | 85\n",
    "53 | How I Met Your Mother | 83\n",
    "53 | Kanye West | 83\n",
    "53 | Tupac Shakur | 83\n",
    "53 | Angelina Jolie | 83\n",
    "53 | John F. Kennedy | 83\n",
    "53 | COVID-19 pandemic | 83\n",
    "53 | Scarlett Johansson | 83\n",
    "53 | List of Marvel Cinematic Universe films | 83\n",
    "61 | Joe Biden | 82\n",
    "62 | Chernobyl disaster | 81\n",
    "63 | France | 80\n",
    "63 | Tom Cruise | 80\n",
    "63 | Ariana Grande | 80\n",
    "66 | Jennifer Aniston | 79\n",
    "66 | Breaking Bad | 79\n",
    "66 | Arnold Schwarzenegger | 79\n",
    "66 | Pablo Escobar | 79\n",
    "70 | Keanu Reeves | 78\n",
    "71 | Mila Kunis | 77\n",
    "71 | Vietnam War | 77\n",
    "71 | Meghan, Duchess of Sussex | 77\n",
    "71 | Queen Victoria | 77\n",
    "71 | Mark Zuckerberg | 77\n",
    "71 | William Shakespeare | 77\n",
    "71 | Jay-Z | 77\n",
    "78 | Earth | 76\n",
    "78 | Bill Gates | 76\n",
    "78 | Muhammad Ali | 76\n",
    "78 | Ted Bundy | 76\n",
    "82 | Nicky Minaj | 75\n",
    "82 | Will Smith | 75\n",
    "84 | Singapore | 74\n",
    "84 | Israel | 74\n",
    "84 | John Cena | 74\n",
    "84 | Bruce Lee | 74\n",
    "84 | Elvis Presley | 74\n",
    "89 | Diana, Princess of Wales | 73\n",
    "89 | Charles Manson | 73\n",
    "89 | Manchester United F.C. | 73\n",
    "92 | Marilyn Monroe | 72\n",
    "93 | Sexual intercourse | 71\n",
    "93 | Katy Perry | 71\n",
    "93 | Winston Churchill | 71\n",
    "93 | Tom Brady | 71\n",
    "93 | Periodic Table | 71\n",
    "93 | Glee (TV series) | 71\n",
    "93 | Brad Pitt | 71\n",
    "93 | Madonna | 71\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some constants..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'pages'\n",
    "\n",
    "# we filter out these elements\n",
    "CLEAN = [\n",
    "  'a[id=\"top\"]',\n",
    "  'a[class=\"mw-selflink selflink\"]',\n",
    "  'a[class=\"image\"]',\n",
    "  'a[class=\"internal\"]',\n",
    "  \"sup\",\n",
    "]\n",
    "\n",
    "# we filter out these links\n",
    "REM_LINKS = [\n",
    "  r\"(\\/wiki\\/File:\\w+)\",\n",
    "  r\"(\\/wiki\\/Special:\\w+)\",\n",
    "  r\"(\\/wiki\\/Template:\\w+)\",\n",
    "  r\"(\\/wiki\\/Category:\\w+)\",\n",
    "  r\"(\\/wiki\\/Portal:\\w+)\",\n",
    "  r\"(\\/wiki\\/Template_talk:\\w+)\",\n",
    "  r\"(\\/wiki\\/Help:\\w+)\",\n",
    "  r\"(\\/wiki\\/Wikipedia:\\w+)\",\n",
    "  r\"(^#\\w+)\",\n",
    "]\n",
    "\n",
    "# main page content selector\n",
    "CONT_SEL = \"div#content\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a function to clean up the page of any unwanted links or elements. Although Wikipedia pages are fairly clean and nice to work with programmatically, there are still certain types of elements that we want to filter out. Such links include self links (links that link back to themselves), image links, internal links, link to files or template pages, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_page(html):\n",
    "  # clean up unwanted links from pages\n",
    "  for c in CLEAN:\n",
    "    els = html.select(f\"{CONT_SEL} {c}\")\n",
    "    for el in els:\n",
    "      el.decompose()\n",
    "\n",
    "  # format remaining links\n",
    "  links = html.select(f\"{CONT_SEL} a\")\n",
    "  for link in links:\n",
    "    # extract href from link\n",
    "    href = link['href']\n",
    "\n",
    "    # extract text of links and remove punctuation\n",
    "    text = re.sub(r\"[\\,\\.\\:\\!\\?]\", \"\", link.text)\n",
    "\n",
    "    # at this stage, we want to further remove certain types of links\n",
    "    # that is: any of the links in REM_LINKS, OR any link that doesn't start with /wiki/\n",
    "    if any([re.match(regex, href) for regex in REM_LINKS]) or not re.match(r\"^\\/wiki\\/\\w+\", href):\n",
    "      link.decompose()\n",
    "    else:\n",
    "      # remove leading /wiki/ from href as it is redundant\n",
    "      href = re.sub(r\"\\/wiki\\/\", \"\", href)\n",
    "\n",
    "      # Here is the 1000 IQ play. We want to preserve the URL of the links but\n",
    "      # also work with them from a cleaner text file. We CAN extract the text\n",
    "      # from the entire page but that would mean losing the hrefs. To solve\n",
    "      # this, we replace the text content of the link with its text AND the\n",
    "      # associated href. THEN we can simply extract the text content of the file\n",
    "      # without losing the href!!1\n",
    "      link.replace_with(f'{{{text}|{href}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 'West_Side_Story_(1961_film)'\n",
    "res = get(f'https://en.wikipedia.org/wiki/{page}')\n",
    "html = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_page(html)\n",
    "\n",
    "# create one parsed page and one clean html page\n",
    "parsed_page = html.getText()\n",
    "html_page = str(html.prettify())\n",
    "\n",
    "# save files\n",
    "parsed_file = open(f\"{DATA_DIR}/{page}.txt\", \"w\")\n",
    "parsed_file.write(parsed_page)\n",
    "parsed_file.close()\n",
    "\n",
    "html_file = open(f\"{DATA_DIR}/{page}.html\", \"w\")\n",
    "html_file.write(html_page)\n",
    "html_file.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
